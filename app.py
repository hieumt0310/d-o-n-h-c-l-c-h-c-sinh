import streamlit as st
import joblib
import numpy as np
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
import joblib

# ===================================
# 1Ô∏è‚É£ T·∫°o dataset m·∫´u (ho·∫∑c d√πng file c·ªßa b·∫°n)
# ===================================
data = {
    'Hours_Study': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Previous Scores': [40, 50, 55, 60, 65, 70, 80, 85, 90, 95],
    'Extracurricular Activities': [0, 1, 0, 1, 0, 1, 1, 0, 1, 0],
    'Sleep Hours': [4, 5, 6, 7, 6, 8, 7, 8, 9, 8],
    'Sample Question Papers Practiced': [2, 3, 4, 5, 6, 7, 8, 9, 10, 10],
    'Grade': [0, 0, 1, 1, 1, 2, 2, 2, 2, 2]  # 0=TB, 1=Kh√°, 2=Gi·ªèi
}
df = pd.DataFrame(data)

# ===================================
# 2Ô∏è‚É£ T√°ch d·ªØ li·ªáu
# ===================================
X = df[['Hours_Study', 'Previous Scores', 'Extracurricular Activities',
        'Sleep Hours', 'Sample Question Papers Practiced']]
y = df['Grade']

# Chia t·∫≠p hu·∫•n luy·ªán / ki·ªÉm tra
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ===================================
# 3Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu
# ===================================
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ===================================
# 4Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh Logistic Regression
# ===================================
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# ===================================
# 5Ô∏è‚É£ L∆∞u l·∫°i model v√† scaler
# ===================================
joblib.dump(model, "student_model.pkl")
joblib.dump(scaler, "student_scaler.pkl")

print("‚úÖ M√¥ h√¨nh v√† scaler ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng!")

# -----------------------------
# 1Ô∏è‚É£ T·∫£i m√¥ h√¨nh v√† scaler
# -----------------------------
model = joblib.load("student_model.pkl")
scaler = joblib.load("student_scaler.pkl")

st.title("üéì ·ª®ng d·ª•ng d·ª± ƒëo√°n h·ªçc l·ª±c h·ªçc sinh")

st.markdown("### ‚úèÔ∏è Nh·∫≠p th√¥ng tin h·ªçc sinh:")

# -----------------------------
# 2Ô∏è‚É£ Nh·∫≠p 5 ƒë·∫∑c tr∆∞ng
# -----------------------------
hours = st.number_input("S·ªë gi·ªù h·ªçc trung b√¨nh m·ªói ng√†y", min_value=0.0, max_value=24.0, value=2.0)
previous = st.number_input("ƒêi·ªÉm trung b√¨nh nƒÉm tr∆∞·ªõc", min_value=0.0, max_value=100.0, value=70.0)
activity = st.selectbox("Tham gia ho·∫°t ƒë·ªông ngo·∫°i kh√≥a?", ["Kh√¥ng", "C√≥"])
sleep = st.number_input("S·ªë gi·ªù ng·ªß trung b√¨nh m·ªói ng√†y", min_value=0.0, max_value=12.0, value=7.0)
papers = st.number_input("S·ªë ƒë·ªÅ luy·ªán t·∫≠p ƒë√£ l√†m", min_value=0, max_value=50, value=5)

# Chuy·ªÉn d·ªØ li·ªáu sang d·∫°ng s·ªë
activity_num = 1 if activity == "C√≥" else 0

# -----------------------------
# 3Ô∏è‚É£ T·∫°o input cho m√¥ h√¨nh
# -----------------------------
input_data = np.array([[hours, previous, activity_num, sleep, papers]])

# Chu·∫©n h√≥a d·ªØ li·ªáu
scaled_data = scaler.transform(input_data)

# -----------------------------
# 4Ô∏è‚É£ D·ª± ƒëo√°n
# -----------------------------
prediction = model.predict(scaled_data)

# -----------------------------
# 5Ô∏è‚É£ Hi·ªÉn th·ªã k·∫øt qu·∫£
# -----------------------------
if prediction[0] == 2:
    st.success("üéì D·ª± ƒëo√°n: H·ªçc sinh c√≥ h·ªçc l·ª±c **Gi·ªèi** ‚≠ê")
elif prediction[0] == 1:
    st.info("üìò D·ª± ƒëo√°n: H·ªçc sinh c√≥ h·ªçc l·ª±c **Kh√°**")
else:
    st.warning("üìô D·ª± ƒëo√°n: H·ªçc sinh c√≥ h·ªçc l·ª±c **Trung b√¨nh** ho·∫∑c y·∫øu")
